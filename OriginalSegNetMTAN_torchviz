digraph {
	graph [size="202.79999999999998,202.79999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2462638841328 [label="
 (2, 13, 288, 384)" fillcolor=darkolivegreen1]
	2462638535344 [label=LogSoftmaxBackward0]
	2462638536208 -> 2462638535344
	2462638536208 [label=ConvolutionBackward0]
	2462638537456 -> 2462638536208
	2462638537456 [label=ConvolutionBackward0]
	2462638526848 -> 2462638537456
	2462638526848 [label=MulBackward0]
	2462638538128 -> 2462638526848
	2462638538128 [label=SigmoidBackward0]
	2462638537984 -> 2462638538128
	2462638537984 [label=CudnnBatchNormBackward0]
	2462638537888 -> 2462638537984
	2462638537888 [label=ConvolutionBackward0]
	2462638537648 -> 2462638537888
	2462638537648 [label=ReluBackward0]
	2462638537408 -> 2462638537648
	2462638537408 [label=CudnnBatchNormBackward0]
	2462638537312 -> 2462638537408
	2462638537312 [label=ConvolutionBackward0]
	2462638537120 -> 2462638537312
	2462638537120 [label=CatBackward0]
	2462638536928 -> 2462638537120
	2462638536928 [label=MaxUnpool2DBackward0]
	2462638536736 -> 2462638536928
	2462638536736 [label=ReluBackward0]
	2462638536640 -> 2462638536736
	2462638536640 [label=CudnnBatchNormBackward0]
	2462638536544 -> 2462638536640
	2462638536544 [label=ConvolutionBackward0]
	2462638536352 -> 2462638536544
	2462638536352 [label=ReluBackward0]
	2462638536112 -> 2462638536352
	2462638536112 [label=CudnnBatchNormBackward0]
	2462638536016 -> 2462638536112
	2462638536016 [label=ConvolutionBackward0]
	2462638535776 -> 2462638536016
	2462638535776 [label=MaxUnpool2DBackward0]
	2462638535536 -> 2462638535776
	2462638535536 [label=ReluBackward0]
	2462638535440 -> 2462638535536
	2462638535440 [label=CudnnBatchNormBackward0]
	2462638535296 -> 2462638535440
	2462638535296 [label=ConvolutionBackward0]
	2462638535104 -> 2462638535296
	2462638535104 [label=ReluBackward0]
	2462638534912 -> 2462638535104
	2462638534912 [label=CudnnBatchNormBackward0]
	2462638534816 -> 2462638534912
	2462638534816 [label=ConvolutionBackward0]
	2462638534576 -> 2462638534816
	2462638534576 [label=ReluBackward0]
	2462638534384 -> 2462638534576
	2462638534384 [label=CudnnBatchNormBackward0]
	2462638534288 -> 2462638534384
	2462638534288 [label=ConvolutionBackward0]
	2462638534048 -> 2462638534288
	2462638534048 [label=MaxUnpool2DBackward0]
	2462638533808 -> 2462638534048
	2462638533808 [label=ReluBackward0]
	2462638533712 -> 2462638533808
	2462638533712 [label=CudnnBatchNormBackward0]
	2462638533616 -> 2462638533712
	2462638533616 [label=ConvolutionBackward0]
	2462638533424 -> 2462638533616
	2462638533424 [label=ReluBackward0]
	2462638533232 -> 2462638533424
	2462638533232 [label=CudnnBatchNormBackward0]
	2462638533136 -> 2462638533232
	2462638533136 [label=ConvolutionBackward0]
	2462638532944 -> 2462638533136
	2462638532944 [label=ReluBackward0]
	2462638532704 -> 2462638532944
	2462638532704 [label=CudnnBatchNormBackward0]
	2462638532608 -> 2462638532704
	2462638532608 [label=ConvolutionBackward0]
	2462638532368 -> 2462638532608
	2462638532368 [label=MaxUnpool2DBackward0]
	2462638532128 -> 2462638532368
	2462638532128 [label=ReluBackward0]
	2462638532032 -> 2462638532128
	2462638532032 [label=CudnnBatchNormBackward0]
	2462638531936 -> 2462638532032
	2462638531936 [label=ConvolutionBackward0]
	2462638531744 -> 2462638531936
	2462638531744 [label=ReluBackward0]
	2462638531552 -> 2462638531744
	2462638531552 [label=CudnnBatchNormBackward0]
	2462638531456 -> 2462638531552
	2462638531456 [label=ConvolutionBackward0]
	2462638531264 -> 2462638531456
	2462638531264 [label=ReluBackward0]
	2462638531072 -> 2462638531264
	2462638531072 [label=CudnnBatchNormBackward0]
	2462638530976 -> 2462638531072
	2462638530976 [label=ConvolutionBackward0]
	2462638530784 -> 2462638530976
	2462638530784 [label=MaxUnpool2DBackward0]
	2462638530592 -> 2462638530784
	2462638530592 [label=MaxPool2DWithIndicesBackward0]
	2462638530496 -> 2462638530592
	2462638530496 [label=ReluBackward0]
	2462638530400 -> 2462638530496
	2462638530400 [label=CudnnBatchNormBackward0]
	2462638530256 -> 2462638530400
	2462638530256 [label=ConvolutionBackward0]
	2462638530064 -> 2462638530256
	2462638530064 [label=ReluBackward0]
	2462638529872 -> 2462638530064
	2462638529872 [label=CudnnBatchNormBackward0]
	2462638529776 -> 2462638529872
	2462638529776 [label=ConvolutionBackward0]
	2462638529536 -> 2462638529776
	2462638529536 [label=ReluBackward0]
	2462638529344 -> 2462638529536
	2462638529344 [label=CudnnBatchNormBackward0]
	2462638529248 -> 2462638529344
	2462638529248 [label=ConvolutionBackward0]
	2462638529056 -> 2462638529248
	2462638529056 [label=MaxPool2DWithIndicesBackward0]
	2462638528864 -> 2462638529056
	2462638528864 [label=ReluBackward0]
	2462638528768 -> 2462638528864
	2462638528768 [label=CudnnBatchNormBackward0]
	2462638528672 -> 2462638528768
	2462638528672 [label=ConvolutionBackward0]
	2462638528480 -> 2462638528672
	2462638528480 [label=ReluBackward0]
	2462638528288 -> 2462638528480
	2462638528288 [label=CudnnBatchNormBackward0]
	2462638528192 -> 2462638528288
	2462638528192 [label=ConvolutionBackward0]
	2462638527952 -> 2462638528192
	2462638527952 [label=ReluBackward0]
	2462638527760 -> 2462638527952
	2462638527760 [label=CudnnBatchNormBackward0]
	2462638527664 -> 2462638527760
	2462638527664 [label=ConvolutionBackward0]
	2462638527472 -> 2462638527664
	2462638527472 [label=MaxPool2DWithIndicesBackward0]
	2462638527280 -> 2462638527472
	2462638527280 [label=ReluBackward0]
	2462638527136 -> 2462638527280
	2462638527136 [label=CudnnBatchNormBackward0]
	2462638526944 -> 2462638527136
	2462638526944 [label=ConvolutionBackward0]
	2462638526800 -> 2462638526944
	2462638526800 [label=ReluBackward0]
	2462638526512 -> 2462638526800
	2462638526512 [label=CudnnBatchNormBackward0]
	2462638526416 -> 2462638526512
	2462638526416 [label=ConvolutionBackward0]
	2462638526224 -> 2462638526416
	2462638526224 [label=ReluBackward0]
	2462638526032 -> 2462638526224
	2462638526032 [label=CudnnBatchNormBackward0]
	2462638525936 -> 2462638526032
	2462638525936 [label=ConvolutionBackward0]
	2462638525744 -> 2462638525936
	2462638525744 [label=MaxPool2DWithIndicesBackward0]
	2462638525552 -> 2462638525744
	2462638525552 [label=ReluBackward0]
	2462638523008 -> 2462638525552
	2462638523008 [label=CudnnBatchNormBackward0]
	2462638522912 -> 2462638523008
	2462638522912 [label=ConvolutionBackward0]
	2462638525024 -> 2462638522912
	2462638525024 [label=ReluBackward0]
	2462638524592 -> 2462638525024
	2462638524592 [label=CudnnBatchNormBackward0]
	2462638524496 -> 2462638524592
	2462638524496 [label=ConvolutionBackward0]
	2462638523968 -> 2462638524496
	2462638523968 [label=MaxPool2DWithIndicesBackward0]
	2462638523440 -> 2462638523968
	2462638523440 [label=ReluBackward0]
	2462638525456 -> 2462638523440
	2462638525456 [label=CudnnBatchNormBackward0]
	2462638525360 -> 2462638525456
	2462638525360 [label=ConvolutionBackward0]
	2462638525168 -> 2462638525360
	2462638525168 [label=ReluBackward0]
	2462638522672 -> 2462638525168
	2462638522672 [label=CudnnBatchNormBackward0]
	2462638522576 -> 2462638522672
	2462638522576 [label=ConvolutionBackward0]
	2462638524832 -> 2462638522576
	2462638832144 [label="encoder_block.0.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	2462638832144 -> 2462638524832
	2462638524832 [label=AccumulateGrad]
	2462638524880 -> 2462638522576
	2462638831824 [label="encoder_block.0.0.bias
 (64)" fillcolor=lightblue]
	2462638831824 -> 2462638524880
	2462638524880 [label=AccumulateGrad]
	2462638522624 -> 2462638522672
	2462638832064 [label="encoder_block.0.1.weight
 (64)" fillcolor=lightblue]
	2462638832064 -> 2462638522624
	2462638522624 [label=AccumulateGrad]
	2462638522768 -> 2462638522672
	2462638832384 [label="encoder_block.0.1.bias
 (64)" fillcolor=lightblue]
	2462638832384 -> 2462638522768
	2462638522768 [label=AccumulateGrad]
	2462638525216 -> 2462638525360
	2462638828544 [label="conv_block_enc.0.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2462638828544 -> 2462638525216
	2462638525216 [label=AccumulateGrad]
	2462638525264 -> 2462638525360
	2462638828464 [label="conv_block_enc.0.0.bias
 (64)" fillcolor=lightblue]
	2462638828464 -> 2462638525264
	2462638525264 [label=AccumulateGrad]
	2462638525408 -> 2462638525456
	2462638828064 [label="conv_block_enc.0.1.weight
 (64)" fillcolor=lightblue]
	2462638828064 -> 2462638525408
	2462638525408 [label=AccumulateGrad]
	2462638523536 -> 2462638525456
	2462638828224 [label="conv_block_enc.0.1.bias
 (64)" fillcolor=lightblue]
	2462638828224 -> 2462638523536
	2462638523536 [label=AccumulateGrad]
	2462638524016 -> 2462638524496
	2462638833264 [label="encoder_block.1.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2462638833264 -> 2462638524016
	2462638524016 [label=AccumulateGrad]
	2462638524064 -> 2462638524496
	2462638833344 [label="encoder_block.1.0.bias
 (128)" fillcolor=lightblue]
	2462638833344 -> 2462638524064
	2462638524064 [label=AccumulateGrad]
	2462638524544 -> 2462638524592
	2462638833424 [label="encoder_block.1.1.weight
 (128)" fillcolor=lightblue]
	2462638833424 -> 2462638524544
	2462638524544 [label=AccumulateGrad]
	2462638522480 -> 2462638524592
	2462638833584 [label="encoder_block.1.1.bias
 (128)" fillcolor=lightblue]
	2462638833584 -> 2462638522480
	2462638522480 [label=AccumulateGrad]
	2462638525072 -> 2462638522912
	2462638826464 [label="conv_block_enc.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2462638826464 -> 2462638525072
	2462638525072 [label=AccumulateGrad]
	2462638525120 -> 2462638522912
	2462638826864 [label="conv_block_enc.1.0.bias
 (128)" fillcolor=lightblue]
	2462638826864 -> 2462638525120
	2462638525120 [label=AccumulateGrad]
	2462638522960 -> 2462638523008
	2462638826704 [label="conv_block_enc.1.1.weight
 (128)" fillcolor=lightblue]
	2462638826704 -> 2462638522960
	2462638522960 [label=AccumulateGrad]
	2462638525648 -> 2462638523008
	2462638826624 [label="conv_block_enc.1.1.bias
 (128)" fillcolor=lightblue]
	2462638826624 -> 2462638525648
	2462638525648 [label=AccumulateGrad]
	2462638525792 -> 2462638525936
	2462638593808 [label="encoder_block.2.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2462638593808 -> 2462638525792
	2462638525792 [label=AccumulateGrad]
	2462638525840 -> 2462638525936
	2462638593888 [label="encoder_block.2.0.bias
 (256)" fillcolor=lightblue]
	2462638593888 -> 2462638525840
	2462638525840 [label=AccumulateGrad]
	2462638525984 -> 2462638526032
	2462638593968 [label="encoder_block.2.1.weight
 (256)" fillcolor=lightblue]
	2462638593968 -> 2462638525984
	2462638525984 [label=AccumulateGrad]
	2462638526128 -> 2462638526032
	2462638593648 [label="encoder_block.2.1.bias
 (256)" fillcolor=lightblue]
	2462638593648 -> 2462638526128
	2462638526128 [label=AccumulateGrad]
	2462638526272 -> 2462638526416
	2462638824944 [label="conv_block_enc.2.0.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2462638824944 -> 2462638526272
	2462638526272 [label=AccumulateGrad]
	2462638526320 -> 2462638526416
	2462638824784 [label="conv_block_enc.2.0.0.bias
 (256)" fillcolor=lightblue]
	2462638824784 -> 2462638526320
	2462638526320 [label=AccumulateGrad]
	2462638526464 -> 2462638526512
	2462638824704 [label="conv_block_enc.2.0.1.weight
 (256)" fillcolor=lightblue]
	2462638824704 -> 2462638526464
	2462638526464 [label=AccumulateGrad]
	2462638526608 -> 2462638526512
	2462638824624 [label="conv_block_enc.2.0.1.bias
 (256)" fillcolor=lightblue]
	2462638824624 -> 2462638526608
	2462638526608 [label=AccumulateGrad]
	2462638526704 -> 2462638526944
	2462384676256 [label="conv_block_enc.2.1.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2462384676256 -> 2462638526704
	2462638526704 [label=AccumulateGrad]
	2462638526752 -> 2462638526944
	2462384676416 [label="conv_block_enc.2.1.0.bias
 (256)" fillcolor=lightblue]
	2462384676416 -> 2462638526752
	2462638526752 [label=AccumulateGrad]
	2462638527088 -> 2462638527136
	2462384676336 [label="conv_block_enc.2.1.1.weight
 (256)" fillcolor=lightblue]
	2462384676336 -> 2462638527088
	2462638527088 [label=AccumulateGrad]
	2462638527328 -> 2462638527136
	2462384676656 [label="conv_block_enc.2.1.1.bias
 (256)" fillcolor=lightblue]
	2462384676656 -> 2462638527328
	2462638527328 [label=AccumulateGrad]
	2462638527568 -> 2462638527664
	2462638591968 [label="encoder_block.3.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2462638591968 -> 2462638527568
	2462638527568 [label=AccumulateGrad]
	2462638527520 -> 2462638527664
	2462638829184 [label="encoder_block.3.0.bias
 (512)" fillcolor=lightblue]
	2462638829184 -> 2462638527520
	2462638527520 [label=AccumulateGrad]
	2462638527712 -> 2462638527760
	2462638831424 [label="encoder_block.3.1.weight
 (512)" fillcolor=lightblue]
	2462638831424 -> 2462638527712
	2462638527712 [label=AccumulateGrad]
	2462638527856 -> 2462638527760
	2462638831344 [label="encoder_block.3.1.bias
 (512)" fillcolor=lightblue]
	2462638831344 -> 2462638527856
	2462638527856 [label=AccumulateGrad]
	2462638528048 -> 2462638528192
	2462384671856 [label="conv_block_enc.3.0.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462384671856 -> 2462638528048
	2462638528048 [label=AccumulateGrad]
	2462638528000 -> 2462638528192
	2462384672016 [label="conv_block_enc.3.0.0.bias
 (512)" fillcolor=lightblue]
	2462384672016 -> 2462638528000
	2462638528000 [label=AccumulateGrad]
	2462638528240 -> 2462638528288
	2462384671936 [label="conv_block_enc.3.0.1.weight
 (512)" fillcolor=lightblue]
	2462384671936 -> 2462638528240
	2462638528240 [label=AccumulateGrad]
	2462638528384 -> 2462638528288
	2462384670336 [label="conv_block_enc.3.0.1.bias
 (512)" fillcolor=lightblue]
	2462384670336 -> 2462638528384
	2462638528384 [label=AccumulateGrad]
	2462638528528 -> 2462638528672
	2462384676096 [label="conv_block_enc.3.1.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462384676096 -> 2462638528528
	2462638528528 [label=AccumulateGrad]
	2462638528576 -> 2462638528672
	2462384676176 [label="conv_block_enc.3.1.0.bias
 (512)" fillcolor=lightblue]
	2462384676176 -> 2462638528576
	2462638528576 [label=AccumulateGrad]
	2462638528720 -> 2462638528768
	2462307119920 [label="conv_block_enc.3.1.1.weight
 (512)" fillcolor=lightblue]
	2462307119920 -> 2462638528720
	2462638528720 [label=AccumulateGrad]
	2462638528960 -> 2462638528768
	2462638831904 [label="conv_block_enc.3.1.1.bias
 (512)" fillcolor=lightblue]
	2462638831904 -> 2462638528960
	2462638528960 [label=AccumulateGrad]
	2462638529104 -> 2462638529248
	2462638829984 [label="encoder_block.4.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462638829984 -> 2462638529104
	2462638529104 [label=AccumulateGrad]
	2462638529152 -> 2462638529248
	2462638829904 [label="encoder_block.4.0.bias
 (512)" fillcolor=lightblue]
	2462638829904 -> 2462638529152
	2462638529152 [label=AccumulateGrad]
	2462638529296 -> 2462638529344
	2462638829424 [label="encoder_block.4.1.weight
 (512)" fillcolor=lightblue]
	2462638829424 -> 2462638529296
	2462638529296 [label=AccumulateGrad]
	2462638529440 -> 2462638529344
	2462638829824 [label="encoder_block.4.1.bias
 (512)" fillcolor=lightblue]
	2462638829824 -> 2462638529440
	2462638529440 [label=AccumulateGrad]
	2462638529584 -> 2462638529776
	2462638817664 [label="conv_block_enc.4.0.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462638817664 -> 2462638529584
	2462638529584 [label=AccumulateGrad]
	2462638529632 -> 2462638529776
	2462638817824 [label="conv_block_enc.4.0.0.bias
 (512)" fillcolor=lightblue]
	2462638817824 -> 2462638529632
	2462638529632 [label=AccumulateGrad]
	2462638529824 -> 2462638529872
	2462638817424 [label="conv_block_enc.4.0.1.weight
 (512)" fillcolor=lightblue]
	2462638817424 -> 2462638529824
	2462638529824 [label=AccumulateGrad]
	2462638529968 -> 2462638529872
	2462638817904 [label="conv_block_enc.4.0.1.bias
 (512)" fillcolor=lightblue]
	2462638817904 -> 2462638529968
	2462638529968 [label=AccumulateGrad]
	2462638530112 -> 2462638530256
	2462638818544 [label="conv_block_enc.4.1.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462638818544 -> 2462638530112
	2462638530112 [label=AccumulateGrad]
	2462638530160 -> 2462638530256
	2462638818144 [label="conv_block_enc.4.1.0.bias
 (512)" fillcolor=lightblue]
	2462638818144 -> 2462638530160
	2462638530160 [label=AccumulateGrad]
	2462638530304 -> 2462638530400
	2462638818624 [label="conv_block_enc.4.1.1.weight
 (512)" fillcolor=lightblue]
	2462638818624 -> 2462638530304
	2462638530304 [label=AccumulateGrad]
	2462638530688 -> 2462638530400
	2462638818704 [label="conv_block_enc.4.1.1.bias
 (512)" fillcolor=lightblue]
	2462638818704 -> 2462638530688
	2462638530688 [label=AccumulateGrad]
	2462638530832 -> 2462638530976
	2462638829104 [label="decoder_block.4.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462638829104 -> 2462638530832
	2462638530832 [label=AccumulateGrad]
	2462638530880 -> 2462638530976
	2462638828944 [label="decoder_block.4.0.bias
 (512)" fillcolor=lightblue]
	2462638828944 -> 2462638530880
	2462638530880 [label=AccumulateGrad]
	2462638531024 -> 2462638531072
	2462638828864 [label="decoder_block.4.1.weight
 (512)" fillcolor=lightblue]
	2462638828864 -> 2462638531024
	2462638531024 [label=AccumulateGrad]
	2462638531168 -> 2462638531072
	2462638828704 [label="decoder_block.4.1.bias
 (512)" fillcolor=lightblue]
	2462638828704 -> 2462638531168
	2462638531168 [label=AccumulateGrad]
	2462638531312 -> 2462638531456
	2462638819344 [label="conv_block_dec.4.0.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462638819344 -> 2462638531312
	2462638531312 [label=AccumulateGrad]
	2462638531360 -> 2462638531456
	2462638819504 [label="conv_block_dec.4.0.0.bias
 (512)" fillcolor=lightblue]
	2462638819504 -> 2462638531360
	2462638531360 [label=AccumulateGrad]
	2462638531504 -> 2462638531552
	2462638819104 [label="conv_block_dec.4.0.1.weight
 (512)" fillcolor=lightblue]
	2462638819104 -> 2462638531504
	2462638531504 [label=AccumulateGrad]
	2462638531648 -> 2462638531552
	2462638819584 [label="conv_block_dec.4.0.1.bias
 (512)" fillcolor=lightblue]
	2462638819584 -> 2462638531648
	2462638531648 [label=AccumulateGrad]
	2462638531792 -> 2462638531936
	2462638819744 [label="conv_block_dec.4.1.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462638819744 -> 2462638531792
	2462638531792 [label=AccumulateGrad]
	2462638531840 -> 2462638531936
	2462638820224 [label="conv_block_dec.4.1.0.bias
 (512)" fillcolor=lightblue]
	2462638820224 -> 2462638531840
	2462638531840 [label=AccumulateGrad]
	2462638531984 -> 2462638532032
	2462638820064 [label="conv_block_dec.4.1.1.weight
 (512)" fillcolor=lightblue]
	2462638820064 -> 2462638531984
	2462638531984 [label=AccumulateGrad]
	2462638532272 -> 2462638532032
	2462638820464 [label="conv_block_dec.4.1.1.bias
 (512)" fillcolor=lightblue]
	2462638820464 -> 2462638532272
	2462638532272 [label=AccumulateGrad]
	2462638532416 -> 2462638532608
	2462638830784 [label="decoder_block.3.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	2462638830784 -> 2462638532416
	2462638532416 [label=AccumulateGrad]
	2462638532464 -> 2462638532608
	2462638830704 [label="decoder_block.3.0.bias
 (256)" fillcolor=lightblue]
	2462638830704 -> 2462638532464
	2462638532464 [label=AccumulateGrad]
	2462638532656 -> 2462638532704
	2462638830624 [label="decoder_block.3.1.weight
 (256)" fillcolor=lightblue]
	2462638830624 -> 2462638532656
	2462638532656 [label=AccumulateGrad]
	2462638532848 -> 2462638532704
	2462638830144 [label="decoder_block.3.1.bias
 (256)" fillcolor=lightblue]
	2462638830144 -> 2462638532848
	2462638532848 [label=AccumulateGrad]
	2462638532992 -> 2462638533136
	2462638825184 [label="conv_block_dec.3.0.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2462638825184 -> 2462638532992
	2462638532992 [label=AccumulateGrad]
	2462638533040 -> 2462638533136
	2462638818464 [label="conv_block_dec.3.0.0.bias
 (256)" fillcolor=lightblue]
	2462638818464 -> 2462638533040
	2462638533040 [label=AccumulateGrad]
	2462638533184 -> 2462638533232
	2462638827664 [label="conv_block_dec.3.0.1.weight
 (256)" fillcolor=lightblue]
	2462638827664 -> 2462638533184
	2462638533184 [label=AccumulateGrad]
	2462638533328 -> 2462638533232
	2462638820944 [label="conv_block_dec.3.0.1.bias
 (256)" fillcolor=lightblue]
	2462638820944 -> 2462638533328
	2462638533328 [label=AccumulateGrad]
	2462638533472 -> 2462638533616
	2462638825744 [label="conv_block_dec.3.1.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2462638825744 -> 2462638533472
	2462638533472 [label=AccumulateGrad]
	2462638533520 -> 2462638533616
	2462638819024 [label="conv_block_dec.3.1.0.bias
 (256)" fillcolor=lightblue]
	2462638819024 -> 2462638533520
	2462638533520 [label=AccumulateGrad]
	2462638533664 -> 2462638533712
	2462638829024 [label="conv_block_dec.3.1.1.weight
 (256)" fillcolor=lightblue]
	2462638829024 -> 2462638533664
	2462638533664 [label=AccumulateGrad]
	2462638533904 -> 2462638533712
	2462638829744 [label="conv_block_dec.3.1.1.bias
 (256)" fillcolor=lightblue]
	2462638829744 -> 2462638533904
	2462638533904 [label=AccumulateGrad]
	2462638534144 -> 2462638534288
	2462638594288 [label="decoder_block.2.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	2462638594288 -> 2462638534144
	2462638534144 [label=AccumulateGrad]
	2462638534192 -> 2462638534288
	2462638593008 [label="decoder_block.2.0.bias
 (128)" fillcolor=lightblue]
	2462638593008 -> 2462638534192
	2462638534192 [label=AccumulateGrad]
	2462638534336 -> 2462638534384
	2462638593088 [label="decoder_block.2.1.weight
 (128)" fillcolor=lightblue]
	2462638593088 -> 2462638534336
	2462638534336 [label=AccumulateGrad]
	2462638534480 -> 2462638534384
	2462638593168 [label="decoder_block.2.1.bias
 (128)" fillcolor=lightblue]
	2462638593168 -> 2462638534480
	2462638534480 [label=AccumulateGrad]
	2462638534624 -> 2462638534816
	2462384680816 [label="conv_block_dec.2.0.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2462384680816 -> 2462638534624
	2462638534624 [label=AccumulateGrad]
	2462638534720 -> 2462638534816
	2462384673136 [label="conv_block_dec.2.0.0.bias
 (128)" fillcolor=lightblue]
	2462384673136 -> 2462638534720
	2462638534720 [label=AccumulateGrad]
	2462638534864 -> 2462638534912
	2462384673056 [label="conv_block_dec.2.0.1.weight
 (128)" fillcolor=lightblue]
	2462384673056 -> 2462638534864
	2462638534864 [label=AccumulateGrad]
	2462638535008 -> 2462638534912
	2462384672736 [label="conv_block_dec.2.0.1.bias
 (128)" fillcolor=lightblue]
	2462384672736 -> 2462638535008
	2462638535008 [label=AccumulateGrad]
	2462638535152 -> 2462638535296
	2462384672336 [label="conv_block_dec.2.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2462384672336 -> 2462638535152
	2462638535152 [label=AccumulateGrad]
	2462638535200 -> 2462638535296
	2462384677536 [label="conv_block_dec.2.1.0.bias
 (128)" fillcolor=lightblue]
	2462384677536 -> 2462638535200
	2462638535200 [label=AccumulateGrad]
	2462638535392 -> 2462638535440
	2462384671056 [label="conv_block_dec.2.1.1.weight
 (128)" fillcolor=lightblue]
	2462384671056 -> 2462638535392
	2462638535392 [label=AccumulateGrad]
	2462638535680 -> 2462638535440
	2462384670976 [label="conv_block_dec.2.1.1.bias
 (128)" fillcolor=lightblue]
	2462384670976 -> 2462638535680
	2462638535680 [label=AccumulateGrad]
	2462638535824 -> 2462638536016
	2462638596288 [label="decoder_block.1.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2462638596288 -> 2462638535824
	2462638535824 [label=AccumulateGrad]
	2462638535872 -> 2462638536016
	2462638596448 [label="decoder_block.1.0.bias
 (64)" fillcolor=lightblue]
	2462638596448 -> 2462638535872
	2462638535872 [label=AccumulateGrad]
	2462638536064 -> 2462638536112
	2462638596528 [label="decoder_block.1.1.weight
 (64)" fillcolor=lightblue]
	2462638596528 -> 2462638536064
	2462638536064 [label=AccumulateGrad]
	2462638536256 -> 2462638536112
	2462638595088 [label="decoder_block.1.1.bias
 (64)" fillcolor=lightblue]
	2462638595088 -> 2462638536256
	2462638536256 [label=AccumulateGrad]
	2462638536400 -> 2462638536544
	2462638825904 [label="conv_block_dec.1.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2462638825904 -> 2462638536400
	2462638536400 [label=AccumulateGrad]
	2462638536448 -> 2462638536544
	2462638825584 [label="conv_block_dec.1.0.bias
 (64)" fillcolor=lightblue]
	2462638825584 -> 2462638536448
	2462638536448 [label=AccumulateGrad]
	2462638536592 -> 2462638536640
	2462638825664 [label="conv_block_dec.1.1.weight
 (64)" fillcolor=lightblue]
	2462638825664 -> 2462638536592
	2462638536592 [label=AccumulateGrad]
	2462638536832 -> 2462638536640
	2462638825424 [label="conv_block_dec.1.1.bias
 (64)" fillcolor=lightblue]
	2462638825424 -> 2462638536832
	2462638536832 [label=AccumulateGrad]
	2462638536976 -> 2462638537120
	2462638536976 [label=ReluBackward0]
	2462638536496 -> 2462638536976
	2462638536496 [label=CudnnBatchNormBackward0]
	2462638536160 -> 2462638536496
	2462638536160 [label=ConvolutionBackward0]
	2462638535488 -> 2462638536160
	2462638535488 [label=UpsampleBilinear2DBackward0]
	2462638534768 -> 2462638535488
	2462638534768 [label=MulBackward0]
	2462638534432 -> 2462638534768
	2462638534432 [label=SigmoidBackward0]
	2462638534000 -> 2462638534432
	2462638534000 [label=CudnnBatchNormBackward0]
	2462638533760 -> 2462638534000
	2462638533760 [label=ConvolutionBackward0]
	2462638533088 -> 2462638533760
	2462638533088 [label=ReluBackward0]
	2462638532320 -> 2462638533088
	2462638532320 [label=CudnnBatchNormBackward0]
	2462638532080 -> 2462638532320
	2462638532080 [label=ConvolutionBackward0]
	2462638531408 -> 2462638532080
	2462638531408 [label=CatBackward0]
	2462638535776 -> 2462638531408
	2462638530736 -> 2462638531408
	2462638530736 [label=ReluBackward0]
	2462638530544 -> 2462638530736
	2462638530544 [label=CudnnBatchNormBackward0]
	2462638530208 -> 2462638530544
	2462638530208 [label=ConvolutionBackward0]
	2462638529488 -> 2462638530208
	2462638529488 [label=UpsampleBilinear2DBackward0]
	2462638528912 -> 2462638529488
	2462638528912 [label=MulBackward0]
	2462638528624 -> 2462638528912
	2462638528624 [label=SigmoidBackward0]
	2462638528336 -> 2462638528624
	2462638528336 [label=CudnnBatchNormBackward0]
	2462638527904 -> 2462638528336
	2462638527904 [label=ConvolutionBackward0]
	2462638527232 -> 2462638527904
	2462638527232 [label=ReluBackward0]
	2462638526560 -> 2462638527232
	2462638526560 [label=CudnnBatchNormBackward0]
	2462638526176 -> 2462638526560
	2462638526176 [label=ConvolutionBackward0]
	2462638525600 -> 2462638526176
	2462638525600 [label=CatBackward0]
	2462638534048 -> 2462638525600
	2462638522432 -> 2462638525600
	2462638522432 [label=ReluBackward0]
	2462638523920 -> 2462638522432
	2462638523920 [label=CudnnBatchNormBackward0]
	2462638523392 -> 2462638523920
	2462638523392 [label=ConvolutionBackward0]
	2462638522528 -> 2462638523392
	2462638522528 [label=UpsampleBilinear2DBackward0]
	2462638524688 -> 2462638522528
	2462638524688 [label=MulBackward0]
	2462638524400 -> 2462638524688
	2462638524400 [label=SigmoidBackward0]
	2462638524304 -> 2462638524400
	2462638524304 [label=CudnnBatchNormBackward0]
	2462638524208 -> 2462638524304
	2462638524208 [label=ConvolutionBackward0]
	2462638523824 -> 2462638524208
	2462638523824 [label=ReluBackward0]
	2462638523632 -> 2462638523824
	2462638523632 [label=CudnnBatchNormBackward0]
	2462638523344 -> 2462638523632
	2462638523344 [label=ConvolutionBackward0]
	2462638523152 -> 2462638523344
	2462638523152 [label=CatBackward0]
	2462638532368 -> 2462638523152
	2462638532560 -> 2462638523152
	2462638532560 [label=ReluBackward0]
	2462638963008 -> 2462638532560
	2462638963008 [label=CudnnBatchNormBackward0]
	2462638962912 -> 2462638963008
	2462638962912 [label=ConvolutionBackward0]
	2462638962768 -> 2462638962912
	2462638962768 [label=UpsampleBilinear2DBackward0]
	2462638962576 -> 2462638962768
	2462638962576 [label=MulBackward0]
	2462638962480 -> 2462638962576
	2462638962480 [label=SigmoidBackward0]
	2462638960944 -> 2462638962480
	2462638960944 [label=CudnnBatchNormBackward0]
	2462638960752 -> 2462638960944
	2462638960752 [label=ConvolutionBackward0]
	2462638960080 -> 2462638960752
	2462638960080 [label=ReluBackward0]
	2462638958160 -> 2462638960080
	2462638958160 [label=CudnnBatchNormBackward0]
	2462638957968 -> 2462638958160
	2462638957968 [label=ConvolutionBackward0]
	2462638957392 -> 2462638957968
	2462638957392 [label=CatBackward0]
	2462638530784 -> 2462638957392
	2462638955376 -> 2462638957392
	2462638955376 [label=ReluBackward0]
	2462638954320 -> 2462638955376
	2462638954320 [label=CudnnBatchNormBackward0]
	2462638954032 -> 2462638954320
	2462638954032 [label=ConvolutionBackward0]
	2462638962096 -> 2462638954032
	2462638962096 [label=UpsampleBilinear2DBackward0]
	2462638961520 -> 2462638962096
	2462638961520 [label=MaxPool2DWithIndicesBackward0]
	2462638961232 -> 2462638961520
	2462638961232 [label=ReluBackward0]
	2462638959696 -> 2462638961232
	2462638959696 [label=CudnnBatchNormBackward0]
	2462638959312 -> 2462638959696
	2462638959312 [label=ConvolutionBackward0]
	2462638958832 -> 2462638959312
	2462638958832 [label=MulBackward0]
	2462638956912 -> 2462638958832
	2462638956912 [label=SigmoidBackward0]
	2462638956624 -> 2462638956912
	2462638956624 [label=CudnnBatchNormBackward0]
	2462638956336 -> 2462638956624
	2462638956336 [label=ConvolutionBackward0]
	2462638955088 -> 2462638956336
	2462638955088 [label=ReluBackward0]
	2462638953648 -> 2462638955088
	2462638953648 [label=CudnnBatchNormBackward0]
	2462638953360 -> 2462638953648
	2462638953360 [label=ConvolutionBackward0]
	2462638952784 -> 2462638953360
	2462638952784 [label=CatBackward0]
	2462638529536 -> 2462638952784
	2462638951632 -> 2462638952784
	2462638951632 [label=MaxPool2DWithIndicesBackward0]
	2462638950672 -> 2462638951632
	2462638950672 [label=ReluBackward0]
	2462638950480 -> 2462638950672
	2462638950480 [label=CudnnBatchNormBackward0]
	2462638952592 -> 2462638950480
	2462638952592 [label=ConvolutionBackward0]
	2462638951536 -> 2462638952592
	2462638951536 [label=MulBackward0]
	2462638950384 -> 2462638951536
	2462638950384 [label=SigmoidBackward0]
	2462638948944 -> 2462638950384
	2462638948944 [label=CudnnBatchNormBackward0]
	2462638962432 -> 2462638948944
	2462638962432 [label=ConvolutionBackward0]
	2462638962144 -> 2462638962432
	2462638962144 [label=ReluBackward0]
	2462638961856 -> 2462638962144
	2462638961856 [label=CudnnBatchNormBackward0]
	2462638961712 -> 2462638961856
	2462638961712 [label=ConvolutionBackward0]
	2462638961376 -> 2462638961712
	2462638961376 [label=CatBackward0]
	2462638527952 -> 2462638961376
	2462638961136 -> 2462638961376
	2462638961136 [label=MaxPool2DWithIndicesBackward0]
	2462638960992 -> 2462638961136
	2462638960992 [label=ReluBackward0]
	2462638960800 -> 2462638960992
	2462638960800 [label=CudnnBatchNormBackward0]
	2462638960656 -> 2462638960800
	2462638960656 [label=ConvolutionBackward0]
	2462638960416 -> 2462638960656
	2462638960416 [label=MulBackward0]
	2462638960128 -> 2462638960416
	2462638960128 [label=SigmoidBackward0]
	2462638959984 -> 2462638960128
	2462638959984 [label=CudnnBatchNormBackward0]
	2462638959840 -> 2462638959984
	2462638959840 [label=ConvolutionBackward0]
	2462638959552 -> 2462638959840
	2462638959552 [label=ReluBackward0]
	2462638959264 -> 2462638959552
	2462638959264 [label=CudnnBatchNormBackward0]
	2462638959072 -> 2462638959264
	2462638959072 [label=ConvolutionBackward0]
	2462638958784 -> 2462638959072
	2462638958784 [label=CatBackward0]
	2462638526224 -> 2462638958784
	2462638958496 -> 2462638958784
	2462638958496 [label=MaxPool2DWithIndicesBackward0]
	2462638958400 -> 2462638958496
	2462638958400 [label=ReluBackward0]
	2462638958256 -> 2462638958400
	2462638958256 [label=CudnnBatchNormBackward0]
	2462638958112 -> 2462638958256
	2462638958112 [label=ConvolutionBackward0]
	2462638957824 -> 2462638958112
	2462638957824 [label=MulBackward0]
	2462638957536 -> 2462638957824
	2462638957536 [label=SigmoidBackward0]
	2462638957344 -> 2462638957536
	2462638957344 [label=CudnnBatchNormBackward0]
	2462638957200 -> 2462638957344
	2462638957200 [label=ConvolutionBackward0]
	2462638956960 -> 2462638957200
	2462638956960 [label=ReluBackward0]
	2462638956672 -> 2462638956960
	2462638956672 [label=CudnnBatchNormBackward0]
	2462638956528 -> 2462638956672
	2462638956528 [label=ConvolutionBackward0]
	2462638956192 -> 2462638956528
	2462638956192 [label=CatBackward0]
	2462638525024 -> 2462638956192
	2462638955952 -> 2462638956192
	2462638955952 [label=MaxPool2DWithIndicesBackward0]
	2462638955808 -> 2462638955952
	2462638955808 [label=ReluBackward0]
	2462638955616 -> 2462638955808
	2462638955616 [label=CudnnBatchNormBackward0]
	2462638955472 -> 2462638955616
	2462638955472 [label=ConvolutionBackward0]
	2462638955232 -> 2462638955472
	2462638955232 [label=MulBackward0]
	2462638954944 -> 2462638955232
	2462638954944 [label=SigmoidBackward0]
	2462638954800 -> 2462638954944
	2462638954800 [label=CudnnBatchNormBackward0]
	2462638954656 -> 2462638954800
	2462638954656 [label=ConvolutionBackward0]
	2462638954368 -> 2462638954656
	2462638954368 [label=ReluBackward0]
	2462638954080 -> 2462638954368
	2462638954080 [label=CudnnBatchNormBackward0]
	2462638953888 -> 2462638954080
	2462638953888 [label=ConvolutionBackward0]
	2462638525168 -> 2462638953888
	2462638953600 -> 2462638953888
	2462638820704 [label="encoder_att.0.0.0.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2462638820704 -> 2462638953600
	2462638953600 [label=AccumulateGrad]
	2462638953696 -> 2462638953888
	2462638821104 [label="encoder_att.0.0.0.bias
 (64)" fillcolor=lightblue]
	2462638821104 -> 2462638953696
	2462638953696 [label=AccumulateGrad]
	2462638953984 -> 2462638954080
	2462638821184 [label="encoder_att.0.0.1.weight
 (64)" fillcolor=lightblue]
	2462638821184 -> 2462638953984
	2462638953984 [label=AccumulateGrad]
	2462638954224 -> 2462638954080
	2462638821264 [label="encoder_att.0.0.1.bias
 (64)" fillcolor=lightblue]
	2462638821264 -> 2462638954224
	2462638954224 [label=AccumulateGrad]
	2462638954416 -> 2462638954656
	2462638821824 [label="encoder_att.0.0.3.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2462638821824 -> 2462638954416
	2462638954416 [label=AccumulateGrad]
	2462638954464 -> 2462638954656
	2462638821904 [label="encoder_att.0.0.3.bias
 (64)" fillcolor=lightblue]
	2462638821904 -> 2462638954464
	2462638954464 [label=AccumulateGrad]
	2462638954752 -> 2462638954800
	2462638822064 [label="encoder_att.0.0.4.weight
 (64)" fillcolor=lightblue]
	2462638822064 -> 2462638954752
	2462638954752 [label=AccumulateGrad]
	2462638955040 -> 2462638954800
	2462638821584 [label="encoder_att.0.0.4.bias
 (64)" fillcolor=lightblue]
	2462638821584 -> 2462638955040
	2462638955040 [label=AccumulateGrad]
	2462638523440 -> 2462638955232
	2462638955280 -> 2462638955472
	2462638822224 [label="encoder_block_att.0.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2462638822224 -> 2462638955280
	2462638955280 [label=AccumulateGrad]
	2462638955328 -> 2462638955472
	2462638822144 [label="encoder_block_att.0.0.bias
 (128)" fillcolor=lightblue]
	2462638822144 -> 2462638955328
	2462638955328 [label=AccumulateGrad]
	2462638955520 -> 2462638955616
	2462638821984 [label="encoder_block_att.0.1.weight
 (128)" fillcolor=lightblue]
	2462638821984 -> 2462638955520
	2462638955520 [label=AccumulateGrad]
	2462638956096 -> 2462638955616
	2462384759776 [label="encoder_block_att.0.1.bias
 (128)" fillcolor=lightblue]
	2462384759776 -> 2462638956096
	2462638956096 [label=AccumulateGrad]
	2462638956288 -> 2462638956528
	2462384759136 [label="encoder_att.0.1.0.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2462384759136 -> 2462638956288
	2462638956288 [label=AccumulateGrad]
	2462638956384 -> 2462638956528
	2462384760256 [label="encoder_att.0.1.0.bias
 (128)" fillcolor=lightblue]
	2462384760256 -> 2462638956384
	2462638956384 [label=AccumulateGrad]
	2462638956576 -> 2462638956672
	2462384762256 [label="encoder_att.0.1.1.weight
 (128)" fillcolor=lightblue]
	2462384762256 -> 2462638956576
	2462638956576 [label=AccumulateGrad]
	2462638956768 -> 2462638956672
	2462532959696 [label="encoder_att.0.1.1.bias
 (128)" fillcolor=lightblue]
	2462532959696 -> 2462638956768
	2462638956768 [label=AccumulateGrad]
	2462638957008 -> 2462638957200
	2462532958576 [label="encoder_att.0.1.3.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2462532958576 -> 2462638957008
	2462638957008 [label=AccumulateGrad]
	2462638957056 -> 2462638957200
	2462532958416 [label="encoder_att.0.1.3.bias
 (128)" fillcolor=lightblue]
	2462532958416 -> 2462638957056
	2462638957056 [label=AccumulateGrad]
	2462638957248 -> 2462638957344
	2462532958176 [label="encoder_att.0.1.4.weight
 (128)" fillcolor=lightblue]
	2462532958176 -> 2462638957248
	2462638957248 [label=AccumulateGrad]
	2462638957680 -> 2462638957344
	2462532958816 [label="encoder_att.0.1.4.bias
 (128)" fillcolor=lightblue]
	2462532958816 -> 2462638957680
	2462638957680 [label=AccumulateGrad]
	2462638525552 -> 2462638957824
	2462638957872 -> 2462638958112
	2462534252112 [label="encoder_block_att.1.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2462534252112 -> 2462638957872
	2462638957872 [label=AccumulateGrad]
	2462638957920 -> 2462638958112
	2462534253472 [label="encoder_block_att.1.0.bias
 (256)" fillcolor=lightblue]
	2462534253472 -> 2462638957920
	2462638957920 [label=AccumulateGrad]
	2462638958208 -> 2462638958256
	2462534254192 [label="encoder_block_att.1.1.weight
 (256)" fillcolor=lightblue]
	2462534254192 -> 2462638958208
	2462638958208 [label=AccumulateGrad]
	2462638958688 -> 2462638958256
	2462534250032 [label="encoder_block_att.1.1.bias
 (256)" fillcolor=lightblue]
	2462534250032 -> 2462638958688
	2462638958688 [label=AccumulateGrad]
	2462638958880 -> 2462638959072
	2462638597488 [label="encoder_att.0.2.0.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2462638597488 -> 2462638958880
	2462638958880 [label=AccumulateGrad]
	2462638958928 -> 2462638959072
	2462638597328 [label="encoder_att.0.2.0.bias
 (256)" fillcolor=lightblue]
	2462638597328 -> 2462638958928
	2462638958928 [label=AccumulateGrad]
	2462638959168 -> 2462638959264
	2462638597408 [label="encoder_att.0.2.1.weight
 (256)" fillcolor=lightblue]
	2462638597408 -> 2462638959168
	2462638959168 [label=AccumulateGrad]
	2462638959408 -> 2462638959264
	2462638597088 [label="encoder_att.0.2.1.bias
 (256)" fillcolor=lightblue]
	2462638597088 -> 2462638959408
	2462638959408 [label=AccumulateGrad]
	2462638959600 -> 2462638959840
	2462638593408 [label="encoder_att.0.2.3.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	2462638593408 -> 2462638959600
	2462638959600 [label=AccumulateGrad]
	2462638959648 -> 2462638959840
	2462638592128 [label="encoder_att.0.2.3.bias
 (256)" fillcolor=lightblue]
	2462638592128 -> 2462638959648
	2462638959648 [label=AccumulateGrad]
	2462638959936 -> 2462638959984
	2462638597568 [label="encoder_att.0.2.4.weight
 (256)" fillcolor=lightblue]
	2462638597568 -> 2462638959936
	2462638959936 [label=AccumulateGrad]
	2462638960224 -> 2462638959984
	2462638597248 [label="encoder_att.0.2.4.bias
 (256)" fillcolor=lightblue]
	2462638597248 -> 2462638960224
	2462638960224 [label=AccumulateGrad]
	2462638527280 -> 2462638960416
	2462638960464 -> 2462638960656
	2462534221584 [label="encoder_block_att.2.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2462534221584 -> 2462638960464
	2462638960464 [label=AccumulateGrad]
	2462638960512 -> 2462638960656
	2462534220544 [label="encoder_block_att.2.0.bias
 (512)" fillcolor=lightblue]
	2462534220544 -> 2462638960512
	2462638960512 [label=AccumulateGrad]
	2462638960704 -> 2462638960800
	2462534220464 [label="encoder_block_att.2.1.weight
 (512)" fillcolor=lightblue]
	2462534220464 -> 2462638960704
	2462638960704 [label=AccumulateGrad]
	2462638961280 -> 2462638960800
	2462534220304 [label="encoder_block_att.2.1.bias
 (512)" fillcolor=lightblue]
	2462534220304 -> 2462638961280
	2462638961280 [label=AccumulateGrad]
	2462638961472 -> 2462638961712
	2462638599408 [label="encoder_att.0.3.0.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2462638599408 -> 2462638961472
	2462638961472 [label=AccumulateGrad]
	2462638961568 -> 2462638961712
	2462638599808 [label="encoder_att.0.3.0.bias
 (512)" fillcolor=lightblue]
	2462638599808 -> 2462638961568
	2462638961568 [label=AccumulateGrad]
	2462638961760 -> 2462638961856
	2462638599888 [label="encoder_att.0.3.1.weight
 (512)" fillcolor=lightblue]
	2462638599888 -> 2462638961760
	2462638961760 [label=AccumulateGrad]
	2462638961952 -> 2462638961856
	2462638599968 [label="encoder_att.0.3.1.bias
 (512)" fillcolor=lightblue]
	2462638599968 -> 2462638961952
	2462638961952 [label=AccumulateGrad]
	2462638962192 -> 2462638962432
	2462638600528 [label="encoder_att.0.3.3.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	2462638600528 -> 2462638962192
	2462638962192 [label=AccumulateGrad]
	2462638962240 -> 2462638962432
	2462638600608 [label="encoder_att.0.3.3.bias
 (512)" fillcolor=lightblue]
	2462638600608 -> 2462638962240
	2462638962240 [label=AccumulateGrad]
	2462638948656 -> 2462638948944
	2462638600688 [label="encoder_att.0.3.4.weight
 (512)" fillcolor=lightblue]
	2462638600688 -> 2462638948656
	2462638948656 [label=AccumulateGrad]
	2462638951152 -> 2462638948944
	2462638600768 [label="encoder_att.0.3.4.bias
 (512)" fillcolor=lightblue]
	2462638600768 -> 2462638951152
	2462638951152 [label=AccumulateGrad]
	2462638528864 -> 2462638951536
	2462638952208 -> 2462638952592
	2462534218544 [label="encoder_block_att.3.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462534218544 -> 2462638952208
	2462638952208 [label=AccumulateGrad]
	2462638952304 -> 2462638952592
	2462534217344 [label="encoder_block_att.3.0.bias
 (512)" fillcolor=lightblue]
	2462534217344 -> 2462638952304
	2462638952304 [label=AccumulateGrad]
	2462638949904 -> 2462638950480
	2462534217264 [label="encoder_block_att.3.1.weight
 (512)" fillcolor=lightblue]
	2462534217264 -> 2462638949904
	2462638949904 [label=AccumulateGrad]
	2462638951920 -> 2462638950480
	2462534217104 [label="encoder_block_att.3.1.bias
 (512)" fillcolor=lightblue]
	2462534217104 -> 2462638951920
	2462638951920 [label=AccumulateGrad]
	2462638952880 -> 2462638953360
	2462638604208 [label="encoder_att.0.4.0.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2462638604208 -> 2462638952880
	2462638952880 [label=AccumulateGrad]
	2462638953072 -> 2462638953360
	2462638591568 [label="encoder_att.0.4.0.bias
 (512)" fillcolor=lightblue]
	2462638591568 -> 2462638953072
	2462638953072 [label=AccumulateGrad]
	2462638953456 -> 2462638953648
	2462638590848 [label="encoder_att.0.4.1.weight
 (512)" fillcolor=lightblue]
	2462638590848 -> 2462638953456
	2462638953456 [label=AccumulateGrad]
	2462638954704 -> 2462638953648
	2462638600288 [label="encoder_att.0.4.1.bias
 (512)" fillcolor=lightblue]
	2462638600288 -> 2462638954704
	2462638954704 [label=AccumulateGrad]
	2462638955184 -> 2462638956336
	2462638588048 [label="encoder_att.0.4.3.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	2462638588048 -> 2462638955184
	2462638955184 [label=AccumulateGrad]
	2462638956048 -> 2462638956336
	2462638595968 [label="encoder_att.0.4.3.bias
 (512)" fillcolor=lightblue]
	2462638595968 -> 2462638956048
	2462638956048 [label=AccumulateGrad]
	2462638956432 -> 2462638956624
	2462638600928 [label="encoder_att.0.4.4.weight
 (512)" fillcolor=lightblue]
	2462638600928 -> 2462638956432
	2462638956432 [label=AccumulateGrad]
	2462638957296 -> 2462638956624
	2462638601008 [label="encoder_att.0.4.4.bias
 (512)" fillcolor=lightblue]
	2462638601008 -> 2462638957296
	2462638957296 [label=AccumulateGrad]
	2462638530496 -> 2462638958832
	2462638959024 -> 2462638959312
	2462534207824 [label="encoder_block_att.4.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462534207824 -> 2462638959024
	2462638959024 [label=AccumulateGrad]
	2462638959120 -> 2462638959312
	2462534208224 [label="encoder_block_att.4.0.bias
 (512)" fillcolor=lightblue]
	2462534208224 -> 2462638959120
	2462638959120 [label=AccumulateGrad]
	2462638959504 -> 2462638959696
	2462534207024 [label="encoder_block_att.4.1.weight
 (512)" fillcolor=lightblue]
	2462534207024 -> 2462638959504
	2462638959504 [label=AccumulateGrad]
	2462638961808 -> 2462638959696
	2462534206864 [label="encoder_block_att.4.1.bias
 (512)" fillcolor=lightblue]
	2462534206864 -> 2462638961808
	2462638961808 [label=AccumulateGrad]
	2462638962288 -> 2462638954032
	2462534206064 [label="decoder_block_att.4.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2462534206064 -> 2462638962288
	2462638962288 [label=AccumulateGrad]
	2462638962336 -> 2462638954032
	2462534205904 [label="decoder_block_att.4.0.bias
 (512)" fillcolor=lightblue]
	2462534205904 -> 2462638962336
	2462638962336 [label=AccumulateGrad]
	2462638954128 -> 2462638954320
	2462534205824 [label="decoder_block_att.4.1.weight
 (512)" fillcolor=lightblue]
	2462534205824 -> 2462638954128
	2462638954128 [label=AccumulateGrad]
	2462638955568 -> 2462638954320
	2462534205744 [label="decoder_block_att.4.1.bias
 (512)" fillcolor=lightblue]
	2462534205744 -> 2462638955568
	2462638955568 [label=AccumulateGrad]
	2462638957488 -> 2462638957968
	2462638601408 [label="decoder_att.0.4.0.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2462638601408 -> 2462638957488
	2462638957488 [label=AccumulateGrad]
	2462638957584 -> 2462638957968
	2462638595808 [label="decoder_att.0.4.0.bias
 (512)" fillcolor=lightblue]
	2462638595808 -> 2462638957584
	2462638957584 [label=AccumulateGrad]
	2462638958064 -> 2462638958160
	2462638595728 [label="decoder_att.0.4.1.weight
 (512)" fillcolor=lightblue]
	2462638595728 -> 2462638958064
	2462638958064 [label=AccumulateGrad]
	2462638958544 -> 2462638958160
	2462638601488 [label="decoder_att.0.4.1.bias
 (512)" fillcolor=lightblue]
	2462638601488 -> 2462638958544
	2462638958544 [label=AccumulateGrad]
	2462638960272 -> 2462638960752
	2462638601808 [label="decoder_att.0.4.3.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	2462638601808 -> 2462638960272
	2462638960272 [label=AccumulateGrad]
	2462638960368 -> 2462638960752
	2462638592768 [label="decoder_att.0.4.3.bias
 (512)" fillcolor=lightblue]
	2462638592768 -> 2462638960368
	2462638960368 [label=AccumulateGrad]
	2462638960848 -> 2462638960944
	2462638602048 [label="decoder_att.0.4.4.weight
 (512)" fillcolor=lightblue]
	2462638602048 -> 2462638960848
	2462638960848 [label=AccumulateGrad]
	2462638962672 -> 2462638960944
	2462638602128 [label="decoder_att.0.4.4.bias
 (512)" fillcolor=lightblue]
	2462638602128 -> 2462638962672
	2462638962672 [label=AccumulateGrad]
	2462638532128 -> 2462638962576
	2462638962816 -> 2462638962912
	2462534216144 [label="decoder_block_att.3.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	2462534216144 -> 2462638962816
	2462638962816 [label=AccumulateGrad]
	2462638962864 -> 2462638962912
	2462534216064 [label="decoder_block_att.3.0.bias
 (256)" fillcolor=lightblue]
	2462534216064 -> 2462638962864
	2462638962864 [label=AccumulateGrad]
	2462638962960 -> 2462638963008
	2462534216304 [label="decoder_block_att.3.1.weight
 (256)" fillcolor=lightblue]
	2462534216304 -> 2462638962960
	2462638962960 [label=AccumulateGrad]
	2462638963104 -> 2462638963008
	2462534216464 [label="decoder_block_att.3.1.bias
 (256)" fillcolor=lightblue]
	2462534216464 -> 2462638963104
	2462638963104 [label=AccumulateGrad]
	2462638523200 -> 2462638523344
	2462638602688 [label="decoder_att.0.3.0.weight
 (256, 768, 1, 1)" fillcolor=lightblue]
	2462638602688 -> 2462638523200
	2462638523200 [label=AccumulateGrad]
	2462638523248 -> 2462638523344
	2462638602768 [label="decoder_att.0.3.0.bias
 (256)" fillcolor=lightblue]
	2462638602768 -> 2462638523248
	2462638523248 [label=AccumulateGrad]
	2462638523584 -> 2462638523632
	2462638602848 [label="decoder_att.0.3.1.weight
 (256)" fillcolor=lightblue]
	2462638602848 -> 2462638523584
	2462638523584 [label=AccumulateGrad]
	2462638523728 -> 2462638523632
	2462638603008 [label="decoder_att.0.3.1.bias
 (256)" fillcolor=lightblue]
	2462638603008 -> 2462638523728
	2462638523728 [label=AccumulateGrad]
	2462638523872 -> 2462638524208
	2462638603408 [label="decoder_att.0.3.3.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	2462638603408 -> 2462638523872
	2462638523872 [label=AccumulateGrad]
	2462638524112 -> 2462638524208
	2462638603488 [label="decoder_att.0.3.3.bias
 (256)" fillcolor=lightblue]
	2462638603488 -> 2462638524112
	2462638524112 [label=AccumulateGrad]
	2462638524256 -> 2462638524304
	2462638603568 [label="decoder_att.0.3.4.weight
 (256)" fillcolor=lightblue]
	2462638603568 -> 2462638524256
	2462638524256 [label=AccumulateGrad]
	2462638524784 -> 2462638524304
	2462638603728 [label="decoder_att.0.3.4.bias
 (256)" fillcolor=lightblue]
	2462638603728 -> 2462638524784
	2462638524784 [label=AccumulateGrad]
	2462638533808 -> 2462638524688
	2462638522720 -> 2462638523392
	2462534219184 [label="decoder_block_att.2.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	2462534219184 -> 2462638522720
	2462638522720 [label=AccumulateGrad]
	2462638522816 -> 2462638523392
	2462534219104 [label="decoder_block_att.2.0.bias
 (128)" fillcolor=lightblue]
	2462534219104 -> 2462638522816
	2462638522816 [label=AccumulateGrad]
	2462638523488 -> 2462638523920
	2462534219504 [label="decoder_block_att.2.1.weight
 (128)" fillcolor=lightblue]
	2462534219504 -> 2462638523488
	2462638523488 [label=AccumulateGrad]
	2462638522864 -> 2462638523920
	2462534219744 [label="decoder_block_att.2.1.bias
 (128)" fillcolor=lightblue]
	2462534219744 -> 2462638522864
	2462638522864 [label=AccumulateGrad]
	2462638525696 -> 2462638526176
	2462638598048 [label="decoder_att.0.2.0.weight
 (128, 384, 1, 1)" fillcolor=lightblue]
	2462638598048 -> 2462638525696
	2462638525696 [label=AccumulateGrad]
	2462638525888 -> 2462638526176
	2462638598208 [label="decoder_att.0.2.0.bias
 (128)" fillcolor=lightblue]
	2462638598208 -> 2462638525888
	2462638525888 [label=AccumulateGrad]
	2462638526368 -> 2462638526560
	2462638598128 [label="decoder_att.0.2.1.weight
 (128)" fillcolor=lightblue]
	2462638598128 -> 2462638526368
	2462638526368 [label=AccumulateGrad]
	2462638526896 -> 2462638526560
	2462638597648 [label="decoder_att.0.2.1.bias
 (128)" fillcolor=lightblue]
	2462638597648 -> 2462638526896
	2462638526896 [label=AccumulateGrad]
	2462638527376 -> 2462638527904
	2462638598848 [label="decoder_att.0.2.3.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2462638598848 -> 2462638527376
	2462638527376 [label=AccumulateGrad]
	2462638527616 -> 2462638527904
	2462638598768 [label="decoder_att.0.2.3.bias
 (128)" fillcolor=lightblue]
	2462638598768 -> 2462638527616
	2462638527616 [label=AccumulateGrad]
	2462638528144 -> 2462638528336
	2462638598288 [label="decoder_att.0.2.4.weight
 (128)" fillcolor=lightblue]
	2462638598288 -> 2462638528144
	2462638528144 [label=AccumulateGrad]
	2462638529200 -> 2462638528336
	2462638599008 [label="decoder_att.0.2.4.bias
 (128)" fillcolor=lightblue]
	2462638599008 -> 2462638529200
	2462638529200 [label=AccumulateGrad]
	2462638535536 -> 2462638528912
	2462638529728 -> 2462638530208
	2462534245232 [label="decoder_block_att.1.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2462534245232 -> 2462638529728
	2462638529728 [label=AccumulateGrad]
	2462638529920 -> 2462638530208
	2462534244512 [label="decoder_block_att.1.0.bias
 (64)" fillcolor=lightblue]
	2462534244512 -> 2462638529920
	2462638529920 [label=AccumulateGrad]
	2462638530448 -> 2462638530544
	2462534220944 [label="decoder_block_att.1.1.weight
 (64)" fillcolor=lightblue]
	2462534220944 -> 2462638530448
	2462638530448 [label=AccumulateGrad]
	2462638531120 -> 2462638530544
	2462534208464 [label="decoder_block_att.1.1.bias
 (64)" fillcolor=lightblue]
	2462534208464 -> 2462638531120
	2462638531120 [label=AccumulateGrad]
	2462638531600 -> 2462638532080
	2462532957616 [label="decoder_att.0.1.0.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	2462532957616 -> 2462638531600
	2462638531600 [label=AccumulateGrad]
	2462638531696 -> 2462638532080
	2462532956496 [label="decoder_att.0.1.0.bias
 (64)" fillcolor=lightblue]
	2462532956496 -> 2462638531696
	2462638531696 [label=AccumulateGrad]
	2462638532224 -> 2462638532320
	2462532956256 [label="decoder_att.0.1.1.weight
 (64)" fillcolor=lightblue]
	2462532956256 -> 2462638532224
	2462638532224 [label=AccumulateGrad]
	2462638532800 -> 2462638532320
	2462532956176 [label="decoder_att.0.1.1.bias
 (64)" fillcolor=lightblue]
	2462532956176 -> 2462638532800
	2462638532800 [label=AccumulateGrad]
	2462638533280 -> 2462638533760
	2462532955136 [label="decoder_att.0.1.3.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2462532955136 -> 2462638533280
	2462638533280 [label=AccumulateGrad]
	2462638533376 -> 2462638533760
	2462532955536 [label="decoder_att.0.1.3.bias
 (64)" fillcolor=lightblue]
	2462532955536 -> 2462638533376
	2462638533376 [label=AccumulateGrad]
	2462638533856 -> 2462638534000
	2462532955696 [label="decoder_att.0.1.4.weight
 (64)" fillcolor=lightblue]
	2462532955696 -> 2462638533856
	2462638533856 [label=AccumulateGrad]
	2462638535056 -> 2462638534000
	2462532957856 [label="decoder_att.0.1.4.bias
 (64)" fillcolor=lightblue]
	2462532957856 -> 2462638535056
	2462638535056 [label=AccumulateGrad]
	2462638536736 -> 2462638534768
	2462638535584 -> 2462638536160
	2462384764256 [label="decoder_block_att.0.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2462384764256 -> 2462638535584
	2462638535584 [label=AccumulateGrad]
	2462638535728 -> 2462638536160
	2462384764176 [label="decoder_block_att.0.0.bias
 (64)" fillcolor=lightblue]
	2462384764176 -> 2462638535728
	2462638535728 [label=AccumulateGrad]
	2462638536304 -> 2462638536496
	2462384764096 [label="decoder_block_att.0.1.weight
 (64)" fillcolor=lightblue]
	2462384764096 -> 2462638536304
	2462638536304 [label=AccumulateGrad]
	2462638536784 -> 2462638536496
	2462384764016 [label="decoder_block_att.0.1.bias
 (64)" fillcolor=lightblue]
	2462384764016 -> 2462638536784
	2462638536784 [label=AccumulateGrad]
	2462638537168 -> 2462638537312
	2462638823424 [label="decoder_att.0.0.0.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2462638823424 -> 2462638537168
	2462638537168 [label=AccumulateGrad]
	2462638537216 -> 2462638537312
	2462638823824 [label="decoder_att.0.0.0.bias
 (64)" fillcolor=lightblue]
	2462638823824 -> 2462638537216
	2462638537216 [label=AccumulateGrad]
	2462638537360 -> 2462638537408
	2462638823664 [label="decoder_att.0.0.1.weight
 (64)" fillcolor=lightblue]
	2462638823664 -> 2462638537360
	2462638537360 [label=AccumulateGrad]
	2462638537552 -> 2462638537408
	2462638823584 [label="decoder_att.0.0.1.bias
 (64)" fillcolor=lightblue]
	2462638823584 -> 2462638537552
	2462638537552 [label=AccumulateGrad]
	2462638537696 -> 2462638537888
	2462638823104 [label="decoder_att.0.0.3.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2462638823104 -> 2462638537696
	2462638537696 [label=AccumulateGrad]
	2462638537792 -> 2462638537888
	2462638822944 [label="decoder_att.0.0.3.bias
 (64)" fillcolor=lightblue]
	2462638822944 -> 2462638537792
	2462638537792 [label=AccumulateGrad]
	2462638537936 -> 2462638537984
	2462638822864 [label="decoder_att.0.0.4.weight
 (64)" fillcolor=lightblue]
	2462638822864 -> 2462638537936
	2462638537936 [label=AccumulateGrad]
	2462638538080 -> 2462638537984
	2462638822784 [label="decoder_att.0.0.4.bias
 (64)" fillcolor=lightblue]
	2462638822784 -> 2462638538080
	2462638538080 [label=AccumulateGrad]
	2462638538176 -> 2462638526848
	2462638538176 [label=ReluBackward0]
	2462638537600 -> 2462638538176
	2462638537600 [label=CudnnBatchNormBackward0]
	2462638537264 -> 2462638537600
	2462638537264 [label=ConvolutionBackward0]
	2462638535968 -> 2462638537264
	2462638535968 [label=ReluBackward0]
	2462638534240 -> 2462638535968
	2462638534240 [label=CudnnBatchNormBackward0]
	2462638532896 -> 2462638534240
	2462638532896 [label=ConvolutionBackward0]
	2462638536928 -> 2462638532896
	2462638530928 -> 2462638532896
	2462638831984 [label="decoder_block.0.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2462638831984 -> 2462638530928
	2462638530928 [label=AccumulateGrad]
	2462638531216 -> 2462638532896
	2462638832704 [label="decoder_block.0.0.bias
 (64)" fillcolor=lightblue]
	2462638832704 -> 2462638531216
	2462638531216 [label=AccumulateGrad]
	2462638533568 -> 2462638534240
	2462638832304 [label="decoder_block.0.1.weight
 (64)" fillcolor=lightblue]
	2462638832304 -> 2462638533568
	2462638533568 [label=AccumulateGrad]
	2462638534960 -> 2462638534240
	2462638831584 [label="decoder_block.0.1.bias
 (64)" fillcolor=lightblue]
	2462638831584 -> 2462638534960
	2462638534960 [label=AccumulateGrad]
	2462638536688 -> 2462638537264
	2462638827424 [label="conv_block_dec.0.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2462638827424 -> 2462638536688
	2462638536688 [label=AccumulateGrad]
	2462638537024 -> 2462638537264
	2462638827584 [label="conv_block_dec.0.0.bias
 (64)" fillcolor=lightblue]
	2462638827584 -> 2462638537024
	2462638537024 [label=AccumulateGrad]
	2462638537504 -> 2462638537600
	2462638827104 [label="conv_block_dec.0.1.weight
 (64)" fillcolor=lightblue]
	2462638827104 -> 2462638537504
	2462638537504 [label=AccumulateGrad]
	2462638538032 -> 2462638537600
	2462638827504 [label="conv_block_dec.0.1.bias
 (64)" fillcolor=lightblue]
	2462638827504 -> 2462638538032
	2462638538032 [label=AccumulateGrad]
	2462638527040 -> 2462638537456
	2462534215184 [label="pred_task1.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2462534215184 -> 2462638527040
	2462638527040 [label=AccumulateGrad]
	2462638538368 -> 2462638537456
	2462534215024 [label="pred_task1.0.bias
 (64)" fillcolor=lightblue]
	2462534215024 -> 2462638538368
	2462638538368 [label=AccumulateGrad]
	2462638535920 -> 2462638536208
	2462534215344 [label="pred_task1.1.weight
 (13, 64, 1, 1)" fillcolor=lightblue]
	2462534215344 -> 2462638535920
	2462638535920 [label=AccumulateGrad]
	2462638536880 -> 2462638536208
	2462534215584 [label="pred_task1.1.bias
 (13)" fillcolor=lightblue]
	2462534215584 -> 2462638536880
	2462638536880 [label=AccumulateGrad]
	2462638535344 -> 2462638841328
}
